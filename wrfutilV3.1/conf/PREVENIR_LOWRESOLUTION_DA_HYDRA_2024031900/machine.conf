#!/bin/bash 

#### CLUSTER ###
export MACHINE='HYDRA'                                         # Options HYDRA, FUGAKU , FUGAKUPPS
export ICORE=24                                                # Number of processes per NODE requested to the queue
export INODE=6                                                 # Number of NODES requested to the queue
export QUEUESYS='PBSSSH'                                       # Queue system [SLURM | PBS | SGE | PBS_block | SSH | PJM | PBSSSH ]
export QUEUE='larga'                                            # Queue name (depends on the machine)
export QSUB_ROOT=""
export TOTAL_TIME_LIMIT="24:00:00"                              # When running the entire experiment as a JOB, then this sets the overall time limit.
export TOTAL_MEMORY_LIMIT="100G"                                # How much memory will be requested by the JOB. 
export INTERACTIVE_JOB=0                                        # 1 - means interactive JOB , any other value inidcate regular JOB.

#Fugaku exclusive flags
export LLIO_VOL="/vol0004"                                      # Disk volume to be used in the computation nodes [Fugaku PJM only]
export FUGAKU_GROUP="ra000007"                                  # Fugaku_group associated to the user [Fugaku PJM only]
export PARALLEL_THREADS=1                                       # Set the number of OMP_THREADS in Fugaku [Fugaku PJM only]
export USETMPDIR=0                                              # Wether we will use shared tmp space in Fugaku [Fugaku PJM only]
export SHAREDCACHESIZE=80Gi                                     # Shared tmp space * #of nodes in Fugaku [Fugaku PJM only]

##############
# Paralelizacion
##############
export LETKFNODE=$INODE                                                 # Number of NODES for LETKF
export LETKFSKIP=6                                                      # SKIP value to distribute PROCS along NODES
export LETKFPROC=$(( 10#$LETKFNODE * 10#$ICORE ))                       # Total number of PROCS for LETKF
export LETKFWALLTIME="03:00:00"                                         # Maximum wall time for LETKF (for sequeantial queue JOBS only)
export LETKFOMP=0                                                       # 1 - enable OMP , 0 - disable OMP

export WPSNODE=1                                                        # Number of nodes for WPS (for each ensemble member)
export WPSPROC=4                                                        # Number of procs per node for WPS (if WPSNODE > 1, then ICORE will be assumed)
export WPSSKIP=6                                                        # SKIP value to distribute PROCS along NODES
export WPSWALLTIME="24:00:00"                                           # Maximum wall time for WPS (for sequeantial queue JOBS only)
export WPSOMP=0                                                         # 1 - enable OMP , 0 - disable OMP


export PERTNODE=2                                                       # Number of nodes for PERT MET EM (usually one, this application do not support multiple nodes)
export PERTPROC=4                                                       # Number of procs per node for PERT 
export PERTSKIP=6                                                       # SKIP value to distribute PROCS along NODES 
export PERTWALLTIME="24:00:00"                                          # Maximum wall time for PERT (for sequeantial queue JOBS only)
export PERTOMP=0                                                        # 1 - enable OMP , 0 - disable OMP


export WRFNODE=1                                                        # Number of nodes for WRF (for each ensemble member)
export WRFPROC=24                                                       # Number of procs per node for WRF (if WRFNODE > 1, then ICORE will be assumed)
export WRFSKIP=1                                                        # SKIP value to distribute PROCS along NODES
export WRFWALLTIME="24:00:00"                                           # Maximum wall time for WRF (for sequeantial queue JOBS only)
export WRF_RUNTIME_FLAGS=""                                             # Runtime flags (for example endian conversion)
export WRFOMP=0                                                         # 1 - enable OMP , 0 - disable OMP

### SCALE-RM
export SCALENODE=4                                                       # Number of nodes for WRF (for each ensemble member)
export SCALEPROC=192                                                     # Number of procs per node for WRF (if WRFNODE > 1, then ICORE will be assumed)
export SCALESKIP=12                                                      # SKIP value to distribute PROCS along NODES
export SCALEWALLTIME="01:00:00"                                          # Maximum wall time for WRF (for sequeantial queue JOBS only)
export SCALE_RUNTIME_FLAGS="-Wl,-T"                                      # Runtime flags (for example endian conversion)
export SCALEOMP=1                                                        # 1 - enable OMP , 0 - disable OMP


#Specify machine dependent enviroment settings
if [ $MACHINE = "FUGAKU"  ] ; then
  export LD_LIBRARY_PATH=/lib64:/usr/lib64:/opt/FJSVxtclanga/tcsds-latest/lib64:/opt/FJSVxtclanga/tcsds-latest/lib/:/vol0004/ra000007/data/jruiz/comp_libs_fujitsu/netcdf/lib:$LD_LIBRARY_PATH
  export I_MPI_SPAWN=on
  export MPIEXEC=mpiexec
  export FORT90L="-Wl,-T"                                                # Runtime flags (for example endian conversion)
  export OMP_STACKSIZE=2G

elif [ $MACHINE = "FUGAKUPPS" ] ; then
  . /opt/intel/oneapi/setvars.sh intel64
  export LD_LIBRARY_PATH=/home/ra000007/a04037/data/comp_libs/grib2/lib/:/home/ra000007/a04037/data/comp_libs/netcdf4/lib/:$LD_LIBRARY_PATH
  export I_MPI_SPAWN=on
  set FI_TCP_IFACE=lo
  export MPIEXEC=mpiexec
  ulimit -s unlimited
  export OMP_STACKSIZE=2G

elif [ $MACHINE = "HYDRA" ] ; then
  source /opt/load-libs.sh 1
  export LD_LIBRARY_PATH=/home/jruiz/salidas/libpng-1.2.50/lib/:$LD_LIBRARY_PATH
  export HDF5_USE_FILE_LOCKING=FALSE
  export MPIEXEC=/opt/intel/oneapi/mpi/latest/bin/mpiexec
  ulimit -s unlimited
  export OMP_STACKSIZE=2G
fi

